---
title: "Batch simulation and correction"
author: "Miao Yu"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(mzrtsim)
library(FAMT)
library(isva)
library(RRmix)
```

## Batch simulation

You could use `mzrtsim` to make simulation.

```{r mzrtsim}
simdata <- mzrtsim(npeaks = 1000, ncomp = 0.9, ncond = 2, ncpeaks = 0.05,
  nbatch = 3, nbpeaks = 0.1, npercond = 10, nperbatch = c(8, 5, 7),
  shape = 2, scale = 3, shapersd = 1, scalersd = 0.18, seed = 42)

simdata2 <- mzrtsim(npeaks = 1000, ncomp = 0.3, ncond = 2, ncpeaks = 0.05,
  nbatch = 3, nbpeaks = 0.1, npercond = 10, nperbatch = c(8, 5, 7),
  shape = 2, scale = 3, shapersd = 1, scalersd = 0.18, seed = 42)

simdata3 <- mzrtsim(npeaks = 1000, ncomp = 0.3, ncond = 2, ncpeaks = 0.05,
  nbatch = 3, nbpeaks = 0.5, npercond = 10, nperbatch = c(8, 5, 7),
  shape = 2, scale = 3, shapersd = 1, scalersd = 0.18, seed = 42)

simdata4 <- mzrtsim(npeaks = 1000, ncomp = 0.3, ncond = 2, ncpeaks = 0.5,
  nbatch = 3, nbpeaks = 0.5, npercond = 10, nperbatch = c(8, 5, 7),
  shape = 2, scale = 3, shapersd = 1, scalersd = 0.18, seed = 42)
```

Here we make a simulation of 1000 peaks with two conditions and three batches. 5 percentage of the peaks were influnced by conditions and 10 percentage of the peaks were influnced by batch effects. The parameters for Weibull distribution of sample mean are 2 for the shape and 3 for the scale.  The parameters for Weibull distribution of sample relative standard deviation(RSD%) are 1 for the shape and 0.18 for the scale. 

We use `ncomp` to control the percentage of indenpendent peaks. 0.9 means 900 compounds generated those 1000 peaks. Other peaks would be randomly generated by the intensity of those 900 original peaks multiple an exponential of random numbers(normal distribution with mean 0 and standard deviation 1). Such setting is used for the simulation of peaks from same compounds in GC/LC-MS data. The conditions and batch effects would show influnces at peaks level to simulate variances before and after instruments analysis.

You could also use `simmzrt` to make simulation from real data. Two type could be used: `e` means simulation from data by sample mean and rsd from Empirical Cumulative Distribution and `f` means simulation from data by sample mean and rsd from Bootstrap sampling. The input data should be matrix with row peaks and column samples.

```{r simmzrt, eval=F}
simdata2 <- simmzrt(data, type = "e", npeaks = 1000, ncomp = 0.5, ncond = 2,
  ncpeaks = 0.05, nbatch = 3, nbpeaks = 0.1, npercond = 10,
  nperbatch = c(8, 5, 7), seed = 42)
```

You could save the simulated data into multiple csv files by `simdata` function. `simraw.csv` could be used for metaboanalyst. `simraw2.csv` show the raw peaks list. `simcon.csv` show peaks influnced by conditions only.`simbatchmatrix.csv` show peaks influnced by batch effects only. `simbat.csv` show peaks influnced by batch effects and conditions. `simcomp.csv` show independent peaks influnced by conditions and batch effects. `simchangec.csv` show the conditions changes of each groups. `simbatchc.csv` show the batch changes of each groups. 

```{r simdata, eval=F}
simdata(sim,name = "sim")
```

### Visulizaiton of simulated data

This is the peaks without condiation and batch effect:

```{r vissim,eval=F}
heatplot(log(simdata$matrix),lv = as.factor(simdata$con))
```

This is the peaks changed by condition:

```{r vissim1,eval=F}
heatplot(log(simdata$cmatrix),lv = as.factor(simdata$con))
```

This is the peaks changed by batch:

```{r vissim2,eval=F}
heatplot(log(simdata$bmatrix),lv = as.factor(simdata$batch))
```

This is the peaks at the compounds level:
```{r vissim3,eval=F}
heatplot(log(simdata$compmatrix),lv = as.factor(simdata$con))
```

This is the simulated peaks:
```{r vissim4,eval=F}
heatplot(log(simdata$data),lv = as.factor(simdata$con))
```

`r sum(simdata$conp %in% simdata$batchp)` peaks are influnced by both condiation and batch effects.

## Basic models of batch effects

Batch effects are the variances caused by factor other than the experimental design. We could simply make a linear model for the intensity of one peak:

$$Intensity =  Average + Condition + Batch + Error$$

Research is focused on condition contribution part and overall average or random error could be estimated. However, we know little about the batch contribution. Sometimes we could use known variables such as injection order or operators as the batch part. However, in most cases we such variable is unknown. Almost all the batch correction methods are trying to use some estimations to balance or remove the batch effect.

For analytical chemistry, internal standards or pool quality control samples are actually standing for the batch contribution part in the model. However, it's impractical to get all the internal standards when the data is collected untargeted. For methods using internal standards or pool quality control samples, the variations among those samples are usually removed as median, quantile, mean or the ratios. Other ways like quantile regression, centering and scaling based on distribution within samples could be treated as using the stable distribution of peaks intensity to remove batch effects. However, here we would turn to the experiments without pooled quality control samples and correction methods which make estimation of batch effects. Some combination methods using pooled quality control samples  or control samples to estimate the batch effect like Remove Unwanted Variation(RUV) would not be covered here.

### Distribution of intensity

Intensity collects from LC/GC-MS always showed a right-skewed distribution. Log transformation is often necessary for further statistical analysis. In some case, a Log-transformed intensity could be visualized easily.

## Evaluation of batch correction

Various methods have been used for batch correction and evaluation. For our simulation, we need some methods to check the performances of correction. Difference analysis would be a common method for evaluation. Then we could check whether this peak is true positive or false positive by settings of the simulation. We will introduce T-test or ANOVA, LIMMA and Bayesian mixture model to find such peaks.

### T-test or ANOVA

If one peak show significant differences among two groups or multiple groups, T-test or ANOVA could be used to find such peaks. However, when multiple hypothesis testings are performed, the probability of false positive would increase. In this case, false discovery rate(FDR) control is required. Q value or adjusted p value could be used in this situation. At certain confidence interval, we could find peaks with significant differences after FDR control.

### LIMMA

Linear Models for MicroArray Data(LIMMA) model could also be used for high-dimensional data like metabolomics. They use a moderated t-statistic to make estimation of the effects called Empirical Bayes Statistics for Differential Expression. It is a hierarchical model to shrink the t-statistic for each peak to all the peaks. Such estimation is more robust. In LIMMA, we could add the known batch effect variable as a covariance in the model. LIMMA is different from t-test or ANOVA while we could still use p value and FDR control on LIMMA results.

### Bayesian mixture model

Another way to make difference analysis is based on Bayesian mixture model without p value. Such model would not use hypothesis testing and directly generate the posterior estimation of parameters. A posterior probability could be used to check whether certain peaks could be related to different condition. If we want to make comparison between classical model like LIMMA and Bayesian mixture model. We need to use simulation to find the cutoff.

## Batch correction methods

### Baseline

```{r limmabaseline}
datacor <- limmafit(simdata$data,simdata$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata,pvalue = datacor$`p-values`,points = 500)

datacor2 <- limmafit(simdata2$data,simdata2$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata2,pvalue = datacor2$`p-values`,points = 500)

datacor3 <- limmafit(simdata3$data,simdata3$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata3,pvalue = datacor3$`p-values`,points = 500)

datacor4 <- limmafit(simdata4$data,simdata4$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata4,pvalue = datacor4$`p-values`,points = 500)
```

### Combat

For Combat methods, you need to use a batch variable to make empirical Bayesian framework based batch correction. However, you could also include such variable in LIMMA model and use empirical Bayesian method. If certain methods could estimate either known or unknown batch effects. Both Combat and LIMMA model could be used. Here we only use LIMMA model and regular F-test to avoid conflict of different evaluation method.

```{r limma}
datacor <- limmafit(simdata$data,simdata$con,simdata$batch)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata,pvalue = datacor$`p-values`,points = 500)

datacor2 <- limmafit(simdata2$data,simdata2$con,simdata2$batch)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata2,pvalue = datacor2$`p-values`,points = 500)

datacor3 <- limmafit(simdata3$data,simdata3$con,simdata3$batch)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata3,pvalue = datacor3$`p-values`,points = 500)

datacor4 <- limmafit(simdata4$data,simdata4$con,simdata4$batch)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata4,pvalue = datacor4$`p-values`,points = 500)
```

### Principal Component Analysis (PCA)

For PCA, the first right singular vectors from singular value decomposition(SVD) are used to stand for the batch variables. The major issue is that such method would not be suitable for the situation with most of the peaks are related to conditions. However, in untargeted analysis, most of the peaks are not related to conditions. We have `pcacor` function to perform such correction.

```{r pcacor}
datacor <- pcacor(simdata$data,simdata$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata,pvalue = datacor$`p-values`,points = 500)

datacor2 <- pcacor(simdata2$data,simdata2$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata2,pvalue = datacor2$`p-values`,points = 500)

datacor3 <- pcacor(simdata3$data,simdata3$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata3,pvalue = datacor3$`p-values`,points = 500)

datacor4 <- pcacor(simdata4$data,simdata4$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata4,pvalue = datacor4$`p-values`,points = 500)
```

### Surrogate Variable Analysis(SVA)

Surrogate variable analysis use an iteratively singular value decomposition(SVD) on the residuals from conditions to find the surrogate variables as batch variables. We have `svacor` function to perform such correction.

```{r sva}
datacor <- svacor(log(simdata$data), simdata$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata,pvalue = datacor$`p-values`,points = 500)

datacor2 <- svacor(simdata2$data,simdata2$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata2,pvalue = datacor2$`p-values`,points = 500)

datacor3 <- svacor(log(simdata3$data), simdata3$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata3,pvalue = datacor3$`p-values`,points = 500)

datacor4 <- svacor(simdata4$data,simdata4$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata4,pvalue = datacor4$`p-values`,points = 500)
```

### Independent Surrogate variable analysis(ISVA)

```{r isva}
datacor <- isvacor(log(simdata$data), simdata$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata,pvalue = datacor$`p-values`,points = 500)

# datacor2 <- isvacor(simdata2$data,simdata2$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
# limmaroc(simdata2,pvalue = datacor2$`p-values`,points = 500)

datacor3 <- svacor(log(simdata3$data), simdata3$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata3,pvalue = datacor$`p-values`,points = 500)

datacor4 <- svacor(simdata4$data,simdata4$con)
# re <- limmaplot(datacor,as.factor(simdata$con))
limmaroc(simdata4,pvalue = datacor4$`p-values`,points = 500)
```

### FMAT

FMAT is different from above methods since it used factor analysis instead of PCA to find the latent factor. In this case, the EM algorithm would be the solution for this model to either find the best numbers of factor or fit the model. We could still use ANOVA and F-test to find the peaks show influnces on the condiation as well as FDR control.

```{r FMAT}
datacor <- famtcor(log(simdata$data), simdata$con)
limmaroc(simdata,pvalue = datacor$`p-values`,points = 500)

datacor2 <- famtcor(log(simdata2$data), simdata2$con)
limmaroc(simdata2,pvalue = datacor2$`p-values`,points = 500)

datacor3 <- famtcor(log(simdata3$data), simdata3$con)
limmaroc(simdata3,pvalue = datacor3$`p-values`,points = 500)

datacor4 <- famtcor(log(simdata4$data), simdata4$con)
limmaroc(simdata4,pvalue = datacor4$`p-values`,points = 500)
```

### RRmix

RRmix extend FMAT to include the estimation of the compound-specific variances and assumptions on the regression coefficients. However, RRmix use a Bayesian mixture model where p-values are hard to get and make comparisions.

```{r RRmix}
datacor <- rrmixcor(log(simdata$data), simdata$con)
limmaroc(simdata,pvalue = 1-datacor$posterior,points = 500)

datacor2 <- rrmixcor(log(simdata2$data), simdata2$con)
limmaroc(simdata2,pvalue = 1-datacor2$posterior,points = 500)

datacor3 <- rrmixcor(log(simdata3$data), simdata3$con)
limmaroc(simdata3,pvalue = 1-datacor3$posterior,points = 500)

#datacor4 <- rrmixcor(log(simdata4$data), simdata4$con)
#limmaroc(simdata4,pvalue = 1-datacor4$posterior,points = 500)
```

